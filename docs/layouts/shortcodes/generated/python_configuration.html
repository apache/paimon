{{/*
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
*/}}
<table class="configuration table table-bordered">
    <thead>
        <tr>
            <th class="text-left" style="width: 20%">Key</th>
            <th class="text-left" style="width: 15%">Default</th>
            <th class="text-left" style="width: 10%">Type</th>
            <th class="text-left" style="width: 55%">Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><h5>blob-as-descriptor</h5></td>
            <td style="word-wrap: break-word;">false</td>
            <td>Boolean</td>
            <td>Write blob field using blob descriptor rather than blob bytes.</td>
        </tr>
        <tr>
            <td><h5>blob.target-file-size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>MemorySize</td>
            <td>Target size of a blob file. Default is value of TARGET_FILE_SIZE.</td>
        </tr>
        <tr>
            <td><h5>bucket</h5></td>
            <td style="word-wrap: break-word;">-1</td>
            <td>Integer</td>
            <td>Bucket number for file store.<br />It should either be equal to -1 (dynamic bucket mode), -2 (postpone bucket mode), or it must be greater than 0 (fixed bucket mode).</td>
        </tr>
        <tr>
            <td><h5>bucket-key</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>Specify the paimon distribution policy. Data is assigned to each bucket according to the hash value of bucket-key.<br />If you specify multiple fields, delimiter is ','.<br />If not specified, the primary key will be used; if there is no primary key, the full row will be used.</td>
        </tr>
        <tr>
            <td><h5>commit.user-prefix</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>Specifies the commit user prefix.</td>
        </tr>
        <tr>
            <td><h5>data-evolution.enabled</h5></td>
            <td style="word-wrap: break-word;">false</td>
            <td>Boolean</td>
            <td>Whether enable data evolution for row tracking table.</td>
        </tr>
        <tr>
            <td><h5>data-file.external-paths</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>The external paths where the data of this table will be written, multiple elements separated by commas.</td>
        </tr>
        <tr>
            <td><h5>data-file.external-paths.specific-fs</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>The specific file system of the external path when data-file.external-paths.strategy is set to specific-fs, should be the prefix scheme of the external path, now supported are s3 and oss.</td>
        </tr>
        <tr>
            <td><h5>data-file.external-paths.strategy</h5></td>
            <td style="word-wrap: break-word;">none</td>
            <td><p>Enum</p></td>
            <td>The strategy of selecting an external path when writing data.<br /><br />Possible values:<ul><li>"none": Do not choose any external storage, data will still be written to the default warehouse path.</li><li>"specific-fs": Select a specific file system as the external path. Currently supported are S3 and OSS.</li><li>"round-robin": When writing a new file, a path is chosen from data-file.external-paths in turn.</li></ul></td>
        </tr>
        <tr>
            <td><h5>file.compression</h5></td>
            <td style="word-wrap: break-word;">"zstd"</td>
            <td>String</td>
            <td>Default file compression. For faster read and write, it is recommended to use zstd.</td>
        </tr>
        <tr>
            <td><h5>file.format</h5></td>
            <td style="word-wrap: break-word;">"parquet"</td>
            <td>String</td>
            <td>Specify the message format of data files, currently orc, parquet and avro are supported.</td>
        </tr>
        <tr>
            <td><h5>incremental-between-timestamp</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>String</td>
            <td>Read incremental changes between start timestamp (exclusive) and end timestamp (inclusive), for example, 't1,t2' means changes between timestamp t1 and timestamp t2.</td>
        </tr>
        <tr>
            <td><h5>row-tracking.enabled</h5></td>
            <td style="word-wrap: break-word;">false</td>
            <td>Boolean</td>
            <td>Whether enable unique row id for append table.</td>
        </tr>
        <tr>
            <td><h5>scan.manifest.parallelism</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>Integer</td>
            <td>The parallelism of scanning manifest files, default value is the size of cpu processor. Note: Scale-up this parameter will increase memory usage while scanning manifest files. We can consider downsize it when we encounter an out of memory exception while scanning</td>
        </tr>
        <tr>
            <td><h5>source.split.open-file-cost</h5></td>
            <td style="word-wrap: break-word;">4 mb</td>
            <td>MemorySize</td>
            <td>Open file cost of a source file. It is used to avoid reading too many files with a source split, which can be very slow.</td>
        </tr>
        <tr>
            <td><h5>source.split.target-size</h5></td>
            <td style="word-wrap: break-word;">128 mb</td>
            <td>MemorySize</td>
            <td>Target size of a source split when scanning a bucket.</td>
        </tr>
        <tr>
            <td><h5>target-file-size</h5></td>
            <td style="word-wrap: break-word;">(none)</td>
            <td>MemorySize</td>
            <td>Target size of a file.<ul><li>primary key table: the default value is 128 MB.</li><li>append table: the default value is 256 MB.</li></ul></td>
        </tr>
    </tbody>
</table>
